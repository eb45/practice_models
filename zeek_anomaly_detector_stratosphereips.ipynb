{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zeek_anomaly_detector_stratosphereips.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZGaj6vEiGT5",
        "outputId": "54386b11-a046-4029-be7d-91d853a9537c"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# This file is part of the Stratosphere Linux IPS\n",
        "# Original Authors:\n",
        "# - Sebastian Garcia. eldraco@gmail.com,\n",
        "#   sebastian.garcia@agents.fel.cvut.cz\n",
        "# - Veronica Valeros. vero.valeros@gmail.com\n",
        "\n",
        "#Edited slightly to accomodate Google Colab\n",
        "\n",
        "\n",
        "#****INSTALLING PYOD****\n",
        "#!pip install pyod            # normal install\n",
        "#!pip install --upgrade pyod  # or update if needed\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from pyod.models.pca import PCA\n",
        "import argparse\n",
        "import warnings\n",
        "\n",
        "\n",
        "# This horrible hack is only to stop sklearn from printing those warnings\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "\n",
        "\n",
        "warnings.warn = warn\n",
        "\n",
        "\n",
        "def detect(file, amountanom, realtime, dumptocsv):\n",
        "    \"\"\"\n",
        "    Function to apply a very simple anomaly detector\n",
        "    amountanom: The top number of anomalies we want to print\n",
        "    realtime: If we want to read the conn.log file in real time (not working)\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a Pandas dataframe from the conn.log\n",
        "    file = \"https://raw.githubusercontent.com/stratosphereips/zeek_anomaly_detector/master/sample-logs/conn.log\"\n",
        "    bro_df = pd.read_csv(file, sep=\"\\t\", comment='#', names=['ts',  'uid', 'id.orig_h', 'id.orig_p', 'id.resp_h', 'id.resp_p', 'proto', 'service', 'duration',  'orig_bytes', 'resp_bytes', 'conn_state', 'local_orig', 'local_resp', 'missed_bytes',  'history', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'tunnel_parents'] )\n",
        "  # In case you need a label, due to some models being able to work in a\n",
        "    # semisupervized mode, then put it here. For now everything is\n",
        "    # 'normal', but we are not using this for detection\n",
        "    bro_df['label'] = 'normal'\n",
        "\n",
        "\n",
        "    # Replace the rows without data (with '-') with 0.\n",
        "    # Even though this may add a bias in the algorithms,\n",
        "    # is better than not using the lines.\n",
        "    # Also fill the no values with 0\n",
        "    # Finally put a type to each column\n",
        "    bro_df['orig_bytes'].replace('-', '0', inplace=True)\n",
        "    bro_df['orig_bytes'] = bro_df['orig_bytes'].fillna(0).astype('int32')\n",
        "    bro_df['resp_bytes'].replace('-', '0', inplace=True)\n",
        "    bro_df['resp_bytes'] = bro_df['resp_bytes'].fillna(0).astype('int32')\n",
        "    bro_df['resp_pkts'].replace('-', '0', inplace=True)\n",
        "    bro_df['resp_pkts'] = bro_df['resp_pkts'].fillna(0).astype('int32')\n",
        "    bro_df['orig_ip_bytes'].replace('-', '0', inplace=True)\n",
        "    bro_df['orig_ip_bytes'] = bro_df['orig_ip_bytes'].fillna(0).astype('int32')\n",
        "    bro_df['resp_ip_bytes'].replace('-', '0', inplace=True)\n",
        "    bro_df['resp_ip_bytes'] = bro_df['resp_ip_bytes'].fillna(0).astype('int32')\n",
        "    bro_df['duration'].replace('-', '0', inplace=True)\n",
        "    bro_df['duration'] = bro_df['duration'].fillna(0).astype('float64')\n",
        "\n",
        "    # Save dataframe to disk as CSV\n",
        "    if dumptocsv != \"None\":\n",
        "        bro_df.to_csv(dumptocsv)\n",
        "\n",
        "    # Add the columns from the log file that we know are numbers. This is only for conn.log files.\n",
        "    X_train = bro_df[['duration', 'orig_bytes', 'id.resp_p', 'resp_bytes', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes']]\n",
        "\n",
        "    # Our y is the label. But we are not using it now.\n",
        "    y = bro_df.label\n",
        "\n",
        "    # The X_test is where we are going to search for anomalies. In our case, its the same set of data than X_train.\n",
        "    X_test = X_train\n",
        "\n",
        "    #################\n",
        "    # Select a model from below\n",
        "\n",
        "    # ABOD class for Angle-base Outlier Detection. For an observation, the\n",
        "    # variance of its weighted cosine scores to all neighbors could be\n",
        "    # viewed as the outlying score.\n",
        "    # clf = ABOD()\n",
        "\n",
        "    # LOF\n",
        "    # clf = LOF()\n",
        "\n",
        "    # CBLOF\n",
        "    # clf = CBLOF()\n",
        "\n",
        "    # LOCI\n",
        "    # clf = LOCI()\n",
        "\n",
        "    # LSCP\n",
        "    # clf = LSCP()\n",
        "\n",
        "    # MCD\n",
        "    # clf = MCD()\n",
        "\n",
        "    # OCSVM\n",
        "    # clf = OCSVM()\n",
        "\n",
        "    # PCA. Good and fast!\n",
        "    clf = PCA()\n",
        "\n",
        "    # SOD\n",
        "    # clf = SOD()\n",
        "\n",
        "    # SO_GAAL\n",
        "    # clf = SO_GALL()\n",
        "\n",
        "    # SOS\n",
        "    # clf = SOS()\n",
        "\n",
        "    # XGBOD\n",
        "    # clf = XGBOD()\n",
        "\n",
        "    # KNN\n",
        "    # Good results but slow\n",
        "    # clf = KNN()\n",
        "    # clf = KNN(n_neighbors=10)\n",
        "    #################\n",
        "    \n",
        "    # extract the value of dataframe to matrix\n",
        "    X_train = X_train.values\n",
        "    \n",
        "    # Fit the model to the train data\n",
        "    clf.fit(X_train)\n",
        "\n",
        "    # get the prediction on the test data\n",
        "    y_test_pred = clf.predict(X_test)  # outlier labels (0 or 1)\n",
        "\n",
        "    y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
        "\n",
        "    # Convert the ndarrays of scores and predictions to  pandas series\n",
        "    scores_series = pd.Series(y_test_scores)\n",
        "    pred_series = pd.Series(y_test_pred)\n",
        "\n",
        "    # Now use the series to add a new column to the X test\n",
        "    X_test['score'] = scores_series.values\n",
        "    X_test['pred'] = pred_series.values\n",
        "\n",
        "    # Add the score to the bro_df also. So we can show it at the end\n",
        "    bro_df['score'] = X_test['score']\n",
        "\n",
        "    # Keep the positive predictions only. That is, keep only what we predict is an anomaly.\n",
        "    X_test_predicted = X_test[X_test.pred == 1]\n",
        "\n",
        "    # Keep the top X amount of anomalies\n",
        "    top10 = X_test_predicted.sort_values(by='score', ascending=False).iloc[:amountanom]\n",
        "\n",
        "    # Print the results\n",
        "    # Find the predicted anomalies in the original bro dataframe, where the rest of the data is\n",
        "    df_to_print = bro_df.iloc[top10.index]\n",
        "    print('\\nFlows of the top anomalies')\n",
        "\n",
        "    # Only print some columns, not all, so its easier to read.\n",
        "    df_to_print = df_to_print.drop(['conn_state', 'history', 'local_orig', 'local_resp', 'missed_bytes', 'ts', 'tunnel_parents', 'uid', 'label'], axis=1)\n",
        "    print(df_to_print)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('Simple Anomaly Detector for Zeek conn.log files. Version: 0.2')\n",
        "    print('Author: Sebastian Garcia (eldraco@gmail.com), Veronica Valeros (vero.valeros@gmail.com)')\n",
        "\n",
        "    # Parse the parameters\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-v', '--verbose', help='Amount of verbosity. This shows more info about the results.', action='store', required=False, type=int)\n",
        "    parser.add_argument('-e', '--debug', help='Amount of debugging. This shows inner information about the program.', action='store', required=False, type=int)\n",
        "    parser.add_argument('-f', '--file', help='Path to the conn.log input file to read.', required=True)\n",
        "    parser.add_argument('-a', '--amountanom', help='Amount of anomalies to show.', required=False, default=10, type=int)\n",
        "    parser.add_argument('-R', '--realtime', help='Read the conn.log in real time.', required=False, type=bool, default=False)\n",
        "    parser.add_argument('-D', '--dumptocsv', help='Dump the conn.log DataFrame to a csv file', required=False)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    detect(args.file, args.amountanom, args.realtime, args.dumptocsv)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple Anomaly Detector for Zeek conn.log files. Version: 0.2\n",
            "Author: Sebastian Garcia (eldraco@gmail.com), Veronica Valeros (vero.valeros@gmail.com)\n",
            "\n",
            "Flows of the top anomalies\n",
            "           id.orig_h  id.orig_p  ... resp_ip_bytes         score\n",
            "24482  192.168.1.125      53510  ...       2524319  3.091147e+07\n",
            "109    192.168.1.125      49188  ...          4828  2.377891e+07\n",
            "35031  192.168.1.125      62788  ...        655203  8.334937e+06\n",
            "28096  192.168.1.125      56689  ...        639202  8.262826e+06\n",
            "28460  192.168.1.125      57002  ...        631468  8.180498e+06\n",
            "26385  192.168.1.125      55173  ...        648260  8.095119e+06\n",
            "29848  192.168.1.125      58222  ...        628643  7.728219e+06\n",
            "33329  192.168.1.125      61298  ...        628283  7.658844e+06\n",
            "31604  192.168.1.125      59773  ...        628283  7.652506e+06\n",
            "819    192.168.1.125      49417  ...          5691  7.261139e+06\n",
            "\n",
            "[10 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}